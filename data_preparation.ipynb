{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61d2e784",
   "metadata": {},
   "source": [
    "# Data Preparation  \n",
    "Consisting of **Data Cleaning**, **Data Exploration**, and **Feature Engineering**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980ab224",
   "metadata": {},
   "source": [
    "## Part 1: Data Discovery + Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "66addae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d94237fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (210000, 36)\n",
      "Test Shape: (40000, 35)\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PATH = \"cattle_data_train.csv\"\n",
    "TEST_PATH = \"cattle_data_test.csv\"\n",
    "\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test = pd.read_csv(TEST_PATH)\n",
    "print(\"Train Shape:\", train.shape)\n",
    "print(\"Test Shape:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7895c0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 210000 entries, 0 to 209999\n",
      "Data columns (total 36 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   Cattle_ID                210000 non-null  object \n",
      " 1   Breed                    210000 non-null  object \n",
      " 2   Climate_Zone             210000 non-null  object \n",
      " 3   Management_System        210000 non-null  object \n",
      " 4   Age_Months               210000 non-null  int64  \n",
      " 5   Weight_kg                210000 non-null  float64\n",
      " 6   Parity                   210000 non-null  int64  \n",
      " 7   Lactation_Stage          210000 non-null  object \n",
      " 8   Days_in_Milk             210000 non-null  int64  \n",
      " 9   Feed_Type                210000 non-null  object \n",
      " 10  Feed_Quantity_kg         199519 non-null  float64\n",
      " 11  Feeding_Frequency        210000 non-null  int64  \n",
      " 12  Water_Intake_L           210000 non-null  float64\n",
      " 13  Walking_Distance_km      210000 non-null  float64\n",
      " 14  Grazing_Duration_hrs     210000 non-null  float64\n",
      " 15  Rumination_Time_hrs      210000 non-null  float64\n",
      " 16  Resting_Hours            210000 non-null  float64\n",
      " 17  Ambient_Temperature_C    210000 non-null  float64\n",
      " 18  Humidity_percent         210000 non-null  float64\n",
      " 19  Housing_Score            203721 non-null  float64\n",
      " 20  FMD_Vaccine              210000 non-null  int64  \n",
      " 21  Brucellosis_Vaccine      210000 non-null  int64  \n",
      " 22  HS_Vaccine               210000 non-null  int64  \n",
      " 23  BQ_Vaccine               210000 non-null  int64  \n",
      " 24  Anthrax_Vaccine          210000 non-null  int64  \n",
      " 25  IBR_Vaccine              210000 non-null  int64  \n",
      " 26  BVD_Vaccine              210000 non-null  int64  \n",
      " 27  Rabies_Vaccine           210000 non-null  int64  \n",
      " 28  Previous_Week_Avg_Yield  210000 non-null  float64\n",
      " 29  Body_Condition_Score     210000 non-null  float64\n",
      " 30  Milking_Interval_hrs     210000 non-null  int64  \n",
      " 31  Date                     210000 non-null  object \n",
      " 32  Farm_ID                  210000 non-null  object \n",
      " 33  Feed_Quantity_lb         199519 non-null  float64\n",
      " 34  Mastitis                 210000 non-null  int64  \n",
      " 35  Milk_Yield_L             210000 non-null  float64\n",
      "dtypes: float64(14), int64(14), object(8)\n",
      "memory usage: 57.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cattle_ID</th>\n",
       "      <th>Breed</th>\n",
       "      <th>Climate_Zone</th>\n",
       "      <th>Management_System</th>\n",
       "      <th>Age_Months</th>\n",
       "      <th>Weight_kg</th>\n",
       "      <th>Parity</th>\n",
       "      <th>Lactation_Stage</th>\n",
       "      <th>Days_in_Milk</th>\n",
       "      <th>Feed_Type</th>\n",
       "      <th>...</th>\n",
       "      <th>BVD_Vaccine</th>\n",
       "      <th>Rabies_Vaccine</th>\n",
       "      <th>Previous_Week_Avg_Yield</th>\n",
       "      <th>Body_Condition_Score</th>\n",
       "      <th>Milking_Interval_hrs</th>\n",
       "      <th>Date</th>\n",
       "      <th>Farm_ID</th>\n",
       "      <th>Feed_Quantity_lb</th>\n",
       "      <th>Mastitis</th>\n",
       "      <th>Milk_Yield_L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CATTLE_133713</td>\n",
       "      <td>Holstein</td>\n",
       "      <td>Tropical</td>\n",
       "      <td>Intensive</td>\n",
       "      <td>114</td>\n",
       "      <td>544.8</td>\n",
       "      <td>4</td>\n",
       "      <td>Mid</td>\n",
       "      <td>62</td>\n",
       "      <td>Concentrates</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.31</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12</td>\n",
       "      <td>2024-01-15</td>\n",
       "      <td>FARM_0301</td>\n",
       "      <td>36.8235</td>\n",
       "      <td>1</td>\n",
       "      <td>12.192634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CATTLE_027003</td>\n",
       "      <td>Holstein</td>\n",
       "      <td>Arid</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>136</td>\n",
       "      <td>298.9</td>\n",
       "      <td>4</td>\n",
       "      <td>Mid</td>\n",
       "      <td>213</td>\n",
       "      <td>Crop_Residues</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.16</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12</td>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>FARM_0219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14.717031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CATTLE_122459</td>\n",
       "      <td>Holstein</td>\n",
       "      <td>Tropical</td>\n",
       "      <td>Semi_Intensive</td>\n",
       "      <td>64</td>\n",
       "      <td>336.6</td>\n",
       "      <td>4</td>\n",
       "      <td>Late</td>\n",
       "      <td>16</td>\n",
       "      <td>Hay</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.07</td>\n",
       "      <td>3.5</td>\n",
       "      <td>12</td>\n",
       "      <td>2024-05-20</td>\n",
       "      <td>FARM_0802</td>\n",
       "      <td>16.0965</td>\n",
       "      <td>0</td>\n",
       "      <td>14.006142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CATTLE_213419</td>\n",
       "      <td>Jersey</td>\n",
       "      <td>Mediterranean</td>\n",
       "      <td>Intensive</td>\n",
       "      <td>58</td>\n",
       "      <td>370.5</td>\n",
       "      <td>1</td>\n",
       "      <td>Early</td>\n",
       "      <td>339</td>\n",
       "      <td>Crop_Residues</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.23</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24</td>\n",
       "      <td>2024-07-22</td>\n",
       "      <td>FARM_0034</td>\n",
       "      <td>40.7925</td>\n",
       "      <td>0</td>\n",
       "      <td>24.324325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CATTLE_106260</td>\n",
       "      <td>Guernsey</td>\n",
       "      <td>Subtropical</td>\n",
       "      <td>Intensive</td>\n",
       "      <td>84</td>\n",
       "      <td>641.5</td>\n",
       "      <td>6</td>\n",
       "      <td>Early</td>\n",
       "      <td>125</td>\n",
       "      <td>Mixed_Feed</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.68</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>FARM_0695</td>\n",
       "      <td>33.7365</td>\n",
       "      <td>1</td>\n",
       "      <td>12.023074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Cattle_ID     Breed   Climate_Zone Management_System  Age_Months  \\\n",
       "0  CATTLE_133713  Holstein       Tropical         Intensive         114   \n",
       "1  CATTLE_027003  Holstein           Arid             Mixed         136   \n",
       "2  CATTLE_122459  Holstein       Tropical    Semi_Intensive          64   \n",
       "3  CATTLE_213419    Jersey  Mediterranean         Intensive          58   \n",
       "4  CATTLE_106260  Guernsey    Subtropical         Intensive          84   \n",
       "\n",
       "   Weight_kg  Parity Lactation_Stage  Days_in_Milk      Feed_Type  ...  \\\n",
       "0      544.8       4             Mid            62   Concentrates  ...   \n",
       "1      298.9       4             Mid           213  Crop_Residues  ...   \n",
       "2      336.6       4            Late            16            Hay  ...   \n",
       "3      370.5       1           Early           339  Crop_Residues  ...   \n",
       "4      641.5       6           Early           125     Mixed_Feed  ...   \n",
       "\n",
       "   BVD_Vaccine  Rabies_Vaccine  Previous_Week_Avg_Yield  Body_Condition_Score  \\\n",
       "0            0               1                     6.31                   3.0   \n",
       "1            0               0                    17.16                   4.0   \n",
       "2            1               0                     4.07                   3.5   \n",
       "3            0               0                    10.23                   3.0   \n",
       "4            1               1                    20.68                   3.0   \n",
       "\n",
       "   Milking_Interval_hrs        Date    Farm_ID  Feed_Quantity_lb  Mastitis  \\\n",
       "0                    12  2024-01-15  FARM_0301           36.8235         1   \n",
       "1                    12  2023-10-31  FARM_0219               NaN         0   \n",
       "2                    12  2024-05-20  FARM_0802           16.0965         0   \n",
       "3                    24  2024-07-22  FARM_0034           40.7925         0   \n",
       "4                    12  2023-01-03  FARM_0695           33.7365         1   \n",
       "\n",
       "   Milk_Yield_L  \n",
       "0     12.192634  \n",
       "1     14.717031  \n",
       "2     14.006142  \n",
       "3     24.324325  \n",
       "4     12.023074  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.info()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "deca641f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in training data\n",
      "Feed_Quantity_kg           10481\n",
      "Feed_Quantity_lb           10481\n",
      "Housing_Score               6279\n",
      "Cattle_ID                      0\n",
      "Brucellosis_Vaccine            0\n",
      "HS_Vaccine                     0\n",
      "BQ_Vaccine                     0\n",
      "Anthrax_Vaccine                0\n",
      "IBR_Vaccine                    0\n",
      "BVD_Vaccine                    0\n",
      "Rabies_Vaccine                 0\n",
      "Previous_Week_Avg_Yield        0\n",
      "Body_Condition_Score           0\n",
      "Milking_Interval_hrs           0\n",
      "Date                           0\n",
      "Farm_ID                        0\n",
      "Mastitis                       0\n",
      "FMD_Vaccine                    0\n",
      "Humidity_percent               0\n",
      "Breed                          0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in testing data\n",
      "Feed_Quantity_kg           2015\n",
      "Feed_Quantity_lb           2015\n",
      "Housing_Score              1221\n",
      "FMD_Vaccine                   0\n",
      "Brucellosis_Vaccine           0\n",
      "HS_Vaccine                    0\n",
      "BQ_Vaccine                    0\n",
      "Anthrax_Vaccine               0\n",
      "IBR_Vaccine                   0\n",
      "Cattle_ID                     0\n",
      "Humidity_percent              0\n",
      "Rabies_Vaccine                0\n",
      "Previous_Week_Avg_Yield       0\n",
      "Body_Condition_Score          0\n",
      "Milking_Interval_hrs          0\n",
      "Date                          0\n",
      "Farm_ID                       0\n",
      "BVD_Vaccine                   0\n",
      "Ambient_Temperature_C         0\n",
      "Breed                         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values in training data\")\n",
    "print(train.isna().sum().sort_values(ascending=False).head(20))\n",
    "print()\n",
    "print(\"Missing values in testing data\")\n",
    "print(test.isna().sum().sort_values(ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8df50a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Are missing masks identical?: True\n",
      "Number of mismatches: 0\n"
     ]
    }
   ],
   "source": [
    "(train[\"Feed_Quantity_kg\"].isna() == train[\"Feed_Quantity_lb\"].isna()).all()\n",
    "mismatch_count = (train[\"Feed_Quantity_kg\"].isna() != train[\"Feed_Quantity_lb\"].isna()).sum()\n",
    "print(mismatch_count)\n",
    "train[train[\"Feed_Quantity_kg\"].isna() != train[\"Feed_Quantity_lb\"].isna()].head()\n",
    "kg_na = train[\"Feed_Quantity_kg\"].isna()\n",
    "lb_na = train[\"Feed_Quantity_lb\"].isna()\n",
    "\n",
    "print(\"Are missing masks identical?:\", (kg_na == lb_na).all())\n",
    "print(\"Number of mismatches:\", (kg_na != lb_na).sum())\n",
    "\n",
    "# Result: Feed_Quantity_kg and Feed_Quantity_lb are both missing at the same time,\n",
    "# therefore, we only need one\n",
    "\n",
    "train = train.drop(\"Feed_Quantity_lb\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "92f8aebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rumination_Time_hrs: 115627\n",
      "Milk_Yield_L: 74\n",
      "Dropped Rumination_Time_hrs column.\n",
      "Negative Milk_Yield_L rows removed: 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cattle_ID</th>\n",
       "      <th>Breed</th>\n",
       "      <th>Climate_Zone</th>\n",
       "      <th>Management_System</th>\n",
       "      <th>Age_Months</th>\n",
       "      <th>Weight_kg</th>\n",
       "      <th>Parity</th>\n",
       "      <th>Lactation_Stage</th>\n",
       "      <th>Days_in_Milk</th>\n",
       "      <th>Feed_Type</th>\n",
       "      <th>...</th>\n",
       "      <th>IBR_Vaccine</th>\n",
       "      <th>BVD_Vaccine</th>\n",
       "      <th>Rabies_Vaccine</th>\n",
       "      <th>Previous_Week_Avg_Yield</th>\n",
       "      <th>Body_Condition_Score</th>\n",
       "      <th>Milking_Interval_hrs</th>\n",
       "      <th>Date</th>\n",
       "      <th>Farm_ID</th>\n",
       "      <th>Mastitis</th>\n",
       "      <th>Milk_Yield_L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CATTLE_133713</td>\n",
       "      <td>Holstein</td>\n",
       "      <td>Tropical</td>\n",
       "      <td>Intensive</td>\n",
       "      <td>114</td>\n",
       "      <td>544.8</td>\n",
       "      <td>4</td>\n",
       "      <td>Mid</td>\n",
       "      <td>62</td>\n",
       "      <td>Concentrates</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.31</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12</td>\n",
       "      <td>2024-01-15</td>\n",
       "      <td>FARM_0301</td>\n",
       "      <td>1</td>\n",
       "      <td>12.192634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CATTLE_027003</td>\n",
       "      <td>Holstein</td>\n",
       "      <td>Arid</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>136</td>\n",
       "      <td>298.9</td>\n",
       "      <td>4</td>\n",
       "      <td>Mid</td>\n",
       "      <td>213</td>\n",
       "      <td>Crop_Residues</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.16</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12</td>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>FARM_0219</td>\n",
       "      <td>0</td>\n",
       "      <td>14.717031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CATTLE_122459</td>\n",
       "      <td>Holstein</td>\n",
       "      <td>Tropical</td>\n",
       "      <td>Semi_Intensive</td>\n",
       "      <td>64</td>\n",
       "      <td>336.6</td>\n",
       "      <td>4</td>\n",
       "      <td>Late</td>\n",
       "      <td>16</td>\n",
       "      <td>Hay</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.07</td>\n",
       "      <td>3.5</td>\n",
       "      <td>12</td>\n",
       "      <td>2024-05-20</td>\n",
       "      <td>FARM_0802</td>\n",
       "      <td>0</td>\n",
       "      <td>14.006142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CATTLE_213419</td>\n",
       "      <td>Jersey</td>\n",
       "      <td>Mediterranean</td>\n",
       "      <td>Intensive</td>\n",
       "      <td>58</td>\n",
       "      <td>370.5</td>\n",
       "      <td>1</td>\n",
       "      <td>Early</td>\n",
       "      <td>339</td>\n",
       "      <td>Crop_Residues</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.23</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24</td>\n",
       "      <td>2024-07-22</td>\n",
       "      <td>FARM_0034</td>\n",
       "      <td>0</td>\n",
       "      <td>24.324325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CATTLE_106260</td>\n",
       "      <td>Guernsey</td>\n",
       "      <td>Subtropical</td>\n",
       "      <td>Intensive</td>\n",
       "      <td>84</td>\n",
       "      <td>641.5</td>\n",
       "      <td>6</td>\n",
       "      <td>Early</td>\n",
       "      <td>125</td>\n",
       "      <td>Mixed_Feed</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.68</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>FARM_0695</td>\n",
       "      <td>1</td>\n",
       "      <td>12.023074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Cattle_ID     Breed   Climate_Zone Management_System  Age_Months  \\\n",
       "0  CATTLE_133713  Holstein       Tropical         Intensive         114   \n",
       "1  CATTLE_027003  Holstein           Arid             Mixed         136   \n",
       "2  CATTLE_122459  Holstein       Tropical    Semi_Intensive          64   \n",
       "3  CATTLE_213419    Jersey  Mediterranean         Intensive          58   \n",
       "4  CATTLE_106260  Guernsey    Subtropical         Intensive          84   \n",
       "\n",
       "   Weight_kg  Parity Lactation_Stage  Days_in_Milk      Feed_Type  ...  \\\n",
       "0      544.8       4             Mid            62   Concentrates  ...   \n",
       "1      298.9       4             Mid           213  Crop_Residues  ...   \n",
       "2      336.6       4            Late            16            Hay  ...   \n",
       "3      370.5       1           Early           339  Crop_Residues  ...   \n",
       "4      641.5       6           Early           125     Mixed_Feed  ...   \n",
       "\n",
       "   IBR_Vaccine  BVD_Vaccine  Rabies_Vaccine  Previous_Week_Avg_Yield  \\\n",
       "0            1            0               1                     6.31   \n",
       "1            0            0               0                    17.16   \n",
       "2            1            1               0                     4.07   \n",
       "3            0            0               0                    10.23   \n",
       "4            0            1               1                    20.68   \n",
       "\n",
       "   Body_Condition_Score  Milking_Interval_hrs        Date    Farm_ID  \\\n",
       "0                   3.0                    12  2024-01-15  FARM_0301   \n",
       "1                   4.0                    12  2023-10-31  FARM_0219   \n",
       "2                   3.5                    12  2024-05-20  FARM_0802   \n",
       "3                   3.0                    24  2024-07-22  FARM_0034   \n",
       "4                   3.0                    12  2023-01-03  FARM_0695   \n",
       "\n",
       "   Mastitis  Milk_Yield_L  \n",
       "0         1     12.192634  \n",
       "1         0     14.717031  \n",
       "2         0     14.006142  \n",
       "3         0     24.324325  \n",
       "4         1     12.023074  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_negatives = {\"Age_Months\": 0, \"Weight_kg\": 0, \"Parity\": 0, \"Days_in_Milk\": 0, \"Feed_Quantity_kg\": 0, \"Water_Intake_L\": 0, \"Walking_Distance_km\": 0, \"Grazing_Duration_hrs\": 0, \"Rumination_Time_hrs\": 0, \"Resting_Hours\": 0, \"Humidity_percent\": 0, \"Previous_Week_Avg_Yield\": 0, \"Milking_Interval_hrs\": 0, \"Milk_Yield_L\": 0}\n",
    "for category in non_negatives:\n",
    "    item = train[category]\n",
    "    for i in item:\n",
    "        if i < 0:\n",
    "            non_negatives[category] += 1\n",
    "for x in non_negatives:\n",
    "    if non_negatives[x] != 0:\n",
    "        print(f\"{x}: {non_negatives[x]}\")\n",
    "\n",
    "# oddly enough, it seems that Rumination_Time_hrs (Hours spent chewing cud per day)\n",
    "# Milk_Yield_L (The total volume of milk produced by the cow in liters during the \n",
    "# recorded milking period; this is the target variable to be predicted.) seem to be\n",
    "# negative a lot.\n",
    "\n",
    "# Therefore, we are going to drop the Rumination_Time_hrs column and the negative\n",
    "# Milk_Yield_L rows\n",
    "\n",
    "if \"Rumination_Time_hrs\" in train.columns:\n",
    "    train = train.drop(columns=[\"Rumination_Time_hrs\"])\n",
    "    print(\"Dropped Rumination_Time_hrs column.\")\n",
    "neg_rows = train[train[\"Milk_Yield_L\"] < 0].shape[0]\n",
    "print(f\"Negative Milk_Yield_L rows removed: {neg_rows}\")\n",
    "\n",
    "train = train[train[\"Milk_Yield_L\"] >= 0].reset_index(drop=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "677aad11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qualitative features: ['Cattle_ID', 'Breed', 'Climate_Zone', 'Management_System', 'Lactation_Stage', 'Feed_Type', 'Date', 'Farm_ID']\n",
      "Cattle_ID: 209892 unique values\n",
      "Breed: 7 unique values\n",
      "Climate_Zone: 6 unique values\n",
      "Management_System: 5 unique values\n",
      "Lactation_Stage: 3 unique values\n",
      "Feed_Type: 8 unique values\n",
      "Date: 1095 unique values\n",
      "Farm_ID: 1000 unique values\n"
     ]
    }
   ],
   "source": [
    "qualitative_cols = train.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "print(\"Qualitative features:\", qualitative_cols)\n",
    "for col in qualitative_cols:\n",
    "    print(f\"{col}: {train[col].nunique()} unique values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6948becc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breed: mean within-group variance = 0.0409\n",
      "Climate_Zone: mean within-group variance = 0.0411\n",
      "Management_System: mean within-group variance = 0.0410\n",
      "Lactation_Stage: mean within-group variance = 0.0410\n",
      "Feed_Type: mean within-group variance = 0.0410\n",
      "Date: mean within-group variance = 0.0407\n",
      "\n",
      "=== Best subgroup features after Farm_ID (lowest variance) ===\n",
      "Date: 0.0407\n",
      "Breed: 0.0409\n",
      "Management_System: 0.0410\n",
      "Feed_Type: 0.0410\n",
      "Lactation_Stage: 0.0410\n",
      "Climate_Zone: 0.0411\n",
      "\n",
      "Best subgroup after Farm_ID: Date\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "We now want to deal with the missing Housing Scores. We are assuming that Housing Score\n",
    "is somewhat correlated with the Farm_ID. A low variance score means we can say that they\n",
    "are properly correlated. This means that when a Housing Score is missing, we can just\n",
    "take the average of the Housing Score of that Farm_ID and plug it in. However, we also\n",
    "want to make sure that the Farm_ID isn't the only thing we're using to group this by,\n",
    "so we will look for the next best thing that lowers the variance when correlated.\n",
    "\"\"\"\n",
    "df_hs = train.dropna(subset=[\"Housing_Score\"])\n",
    "farm_variances = df_hs.groupby(\"Farm_ID\")[\"Housing_Score\"].var()\n",
    "farm_variances_sorted = farm_variances.sort_values(ascending=False)\n",
    "farm_variances_sorted.head(10)   # top 10 highest variance\n",
    "\n",
    "farm_means = df_hs.groupby(\"Farm_ID\")[\"Housing_Score\"].mean()\n",
    "global_mean = train[\"Housing_Score\"].mean()\n",
    "missing_before = train[\"Housing_Score\"].isna().sum()\n",
    "\n",
    "qualitative_cols = train.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "qualitative_cols = [c for c in qualitative_cols if c not in [\"Cattle_ID\", \"Farm_ID\"]]\n",
    "\n",
    "subgroup_results = {}\n",
    "\n",
    "for col in qualitative_cols:\n",
    "    subgroup_var = (\n",
    "        df_hs.groupby([\"Farm_ID\", col])[\"Housing_Score\"].var()\n",
    "    )\n",
    "    mean_var = subgroup_var.mean()\n",
    "    \n",
    "    subgroup_results[col] = mean_var\n",
    "    print(f\"{col}: mean within-group variance = {mean_var:.4f}\")\n",
    "\n",
    "sorted_subgroups = sorted(subgroup_results.items(), key=lambda x: x[1])\n",
    "print(\"\\n=== Best subgroup features after Farm_ID (lowest variance) ===\")\n",
    "for feat, val in sorted_subgroups:\n",
    "    print(f\"{feat}: {val:.4f}\")\n",
    "\n",
    "best_feature = sorted_subgroups[0][0]\n",
    "print(f\"\\nBest subgroup after Farm_ID: {best_feature}\")\n",
    "\n",
    "# We get that Date and Breed have the lowest variance, so we will try group by Farm_ID\n",
    "# then Date then Breed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4647bdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 highest variances (Farm_ID, Date):\n",
      "Farm_ID\n",
      "FARM_0102    0.048945\n",
      "FARM_0877    0.048765\n",
      "FARM_0532    0.048644\n",
      "FARM_0645    0.048580\n",
      "FARM_0795    0.048477\n",
      "FARM_0015    0.048030\n",
      "FARM_0989    0.047777\n",
      "FARM_0411    0.047756\n",
      "FARM_0212    0.047521\n",
      "FARM_0150    0.047442\n",
      "Name: Housing_Score, dtype: float64\n",
      "\n",
      "Mean variance across groups: 0.041010327599322195\n"
     ]
    }
   ],
   "source": [
    "train[\"Date\"] = pd.to_datetime(train[\"Date\"], errors=\"coerce\")\n",
    "df_hs = train.dropna(subset=[\"Housing_Score\"])\n",
    "triple_group_var = (\n",
    "    df_hs.groupby([\"Farm_ID\"])[\"Housing_Score\"].var()\n",
    "          .sort_values(ascending=False)\n",
    ")\n",
    "print(\"Top 10 highest variances (Farm_ID, Date):\")\n",
    "print(triple_group_var.head(10))\n",
    "\n",
    "print(\"\\nMean variance across groups:\", triple_group_var.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ab856e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "We are going to use Farm_ID to get the means to replace the empty Housing\n",
    "Score columns.\n",
    "\"\"\"\n",
    "train[\"Date\"] = pd.to_datetime(train[\"Date\"], errors=\"coerce\")\n",
    "df_hs = train.dropna(subset=[\"Housing_Score\"])\n",
    "farm_date_means = (\n",
    "    df_hs.groupby([\"Farm_ID\"])[\"Housing_Score\"]\n",
    "         .mean()\n",
    ")\n",
    "missing_mask = train[\"Housing_Score\"].isna()\n",
    "keys = list(zip(train.loc[missing_mask, \"Farm_ID\"], train.loc[missing_mask, \"Date\"]))\n",
    "train.loc[missing_mask, \"Housing_Score\"] = [\n",
    "    farm_date_means.get(key, np.nan) for key in keys\n",
    "]\n",
    "farm_means = df_hs.groupby(\"Farm_ID\")[\"Housing_Score\"].mean()\n",
    "still_missing = train[\"Housing_Score\"].isna()\n",
    "\n",
    "train.loc[still_missing, \"Housing_Score\"] = train.loc[still_missing, \"Farm_ID\"].map(farm_means)\n",
    "\n",
    "global_mean = df_hs[\"Housing_Score\"].mean()\n",
    "train[\"Housing_Score\"] = train[\"Housing_Score\"].fillna(global_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "21b53d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breed: mean within-group variance = 14.6411\n",
      "Climate_Zone: mean within-group variance = 15.7531\n",
      "Management_System: mean within-group variance = 15.7533\n",
      "Lactation_Stage: mean within-group variance = 15.7435\n",
      "Feed_Type: mean within-group variance = 15.7533\n",
      "Farm_ID: mean within-group variance = 15.7467\n",
      "\n",
      "=== Best subgroup features (lowest mean variance) ===\n",
      "Breed: 14.6411\n",
      "Lactation_Stage: 15.7435\n",
      "Farm_ID: 15.7467\n",
      "Climate_Zone: 15.7531\n",
      "Management_System: 15.7533\n",
      "Feed_Type: 15.7533\n",
      "\n",
      "Best single subgroup for Feed_Quantity_kg: Breed\n"
     ]
    }
   ],
   "source": [
    "# Now we are going to do the same thing for Feed_Quantity_kg.\n",
    "\n",
    "df_fq = train.dropna(subset=[\"Feed_Quantity_kg\"])\n",
    "qualitative_cols = train.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "qualitative_cols = [c for c in qualitative_cols if c not in [\"Cattle_ID\"]]\n",
    "\n",
    "subgroup_results_fq = {}\n",
    "for col in qualitative_cols:\n",
    "    subgroup_var = df_fq.groupby(col)[\"Feed_Quantity_kg\"].var()\n",
    "    mean_var = subgroup_var.mean()\n",
    "    \n",
    "    subgroup_results_fq[col] = mean_var\n",
    "    print(f\"{col}: mean within-group variance = {mean_var:.4f}\")\n",
    "sorted_subgroups_fq = sorted(subgroup_results_fq.items(), key=lambda x: x[1])\n",
    "\n",
    "print(\"\\n=== Best subgroup features (lowest mean variance) ===\")\n",
    "for feat, val in sorted_subgroups_fq:\n",
    "    print(f\"{feat}: {val:.4f}\")\n",
    "best_feature_fq = sorted_subgroups_fq[0][0]\n",
    "print(f\"\\nBest single subgroup for Feed_Quantity_kg: {best_feature_fq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f921199a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breed + Climate_Zone: mean variance = 14.6153\n",
      "Breed + Management_System: mean variance = 14.7664\n",
      "Breed + Lactation_Stage: mean variance = 14.6518\n",
      "Breed + Feed_Type: mean variance = 14.8448\n",
      "Breed + Farm_ID: mean variance = 15.8105\n",
      "\n",
      "=== Best second-level subgroup after Breed ===\n",
      "Climate_Zone: 14.6153\n",
      "Lactation_Stage: 14.6518\n",
      "Management_System: 14.7664\n",
      "Feed_Type: 14.8448\n",
      "Farm_ID: 15.8105\n",
      "\n",
      "Best subgroup after Breed: Climate_Zone\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" \\nWe were a little confused about why Climate Zone and Farm ID weren't matched for how\\nwell it can be used to predict the Feed_Quantity_kg so we decided to calculate all\\npairwise correlations. \\n\""
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We see that Breed has the lowest variance so we will see if we can group on Breed\n",
    "# and then what is best next:\n",
    "qualitative_cols = train.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "qualitative_cols = [c for c in qualitative_cols if c not in [\"Cattle_ID\", \"Breed\"]]\n",
    "\n",
    "second_level_results = {}\n",
    "for col in qualitative_cols:\n",
    "    subgroup_var = df_fq.groupby([\"Breed\", col])[\"Feed_Quantity_kg\"].var()\n",
    "    mean_var = subgroup_var.mean()\n",
    "    \n",
    "    second_level_results[col] = mean_var\n",
    "    print(f\"Breed + {col}: mean variance = {mean_var:.4f}\")\n",
    "\n",
    "# Sort results from best (lowest variance) to worst\n",
    "sorted_second_level = sorted(second_level_results.items(), key=lambda x: x[1])\n",
    "\n",
    "print(\"\\n=== Best second-level subgroup after Breed ===\")\n",
    "for feat, val in sorted_second_level:\n",
    "    print(f\"{feat}: {val:.4f}\")\n",
    "\n",
    "best_second_feature = sorted_second_level[0][0]\n",
    "print(f\"\\nBest subgroup after Breed: {best_second_feature}\")\n",
    "\n",
    "\"\"\" \n",
    "We were a little confused about why Climate Zone and Farm ID weren't matched for how\n",
    "well it can be used to predict the Feed_Quantity_kg so we decided to calculate all\n",
    "pairwise correlations. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "00573b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Feed_Quantity_kg before imputation: 10480\n",
      "Missing Feed_Quantity_kg after imputation:  0\n",
      "Feed_Quantity_kg imputation by Breed complete.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Since grouping by Breed and any other item doesn't seem to improve the variance that much, \n",
    "we will just be using the mean after grouping by Breed to fill in the values for \n",
    "Feed_Quantity_kg.\n",
    "\"\"\"\n",
    "\n",
    "df_fq = train.dropna(subset=[\"Feed_Quantity_kg\"])\n",
    "breed_means = df_fq.groupby(\"Breed\")[\"Feed_Quantity_kg\"].mean()\n",
    "global_mean_fq = df_fq[\"Feed_Quantity_kg\"].mean()\n",
    "missing_before = train[\"Feed_Quantity_kg\"].isna().sum()\n",
    "train[\"Feed_Quantity_kg\"] = train.apply(\n",
    "    lambda row:\n",
    "        breed_means[row[\"Breed\"]]\n",
    "        if pd.isna(row[\"Feed_Quantity_kg\"]) and row[\"Breed\"] in breed_means\n",
    "        else (global_mean_fq if pd.isna(row[\"Feed_Quantity_kg\"]) else row[\"Feed_Quantity_kg\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "missing_after = train[\"Feed_Quantity_kg\"].isna().sum()\n",
    "print(f\"Missing Feed_Quantity_kg before imputation: {missing_before}\")\n",
    "print(f\"Missing Feed_Quantity_kg after imputation:  {missing_after}\")\n",
    "print(\"Feed_Quantity_kg imputation by Breed complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "86ac1a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in training data\n",
      "Cattle_ID                  0\n",
      "BVD_Vaccine                0\n",
      "FMD_Vaccine                0\n",
      "Brucellosis_Vaccine        0\n",
      "HS_Vaccine                 0\n",
      "BQ_Vaccine                 0\n",
      "Anthrax_Vaccine            0\n",
      "IBR_Vaccine                0\n",
      "Rabies_Vaccine             0\n",
      "Breed                      0\n",
      "Previous_Week_Avg_Yield    0\n",
      "Body_Condition_Score       0\n",
      "Milking_Interval_hrs       0\n",
      "Date                       0\n",
      "Farm_ID                    0\n",
      "Mastitis                   0\n",
      "Housing_Score              0\n",
      "Humidity_percent           0\n",
      "Ambient_Temperature_C      0\n",
      "Resting_Hours              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# SANITY CHECKKKK\n",
    "print(\"Missing values in training data\")\n",
    "print(train.isna().sum().sort_values(ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5042309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions that will be used to calculate correlation\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def cramers_v(x, y):\n",
    "    \"\"\"Cramer's V for categorical-categorical\"\"\"\n",
    "    confusion = pd.crosstab(x, y)\n",
    "    if confusion.shape[0] == 1 or confusion.shape[1] == 1:\n",
    "        return np.nan\n",
    "    chi2 = chi2_contingency(confusion)[0]\n",
    "    n = confusion.sum().sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion.shape\n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n",
    "    rcorr = r - ((r-1)**2)/(n-1)\n",
    "    kcorr = k - ((k-1)**2)/(n-1)\n",
    "    return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))\n",
    "\n",
    "def correlation_ratio(categories, values):\n",
    "    \"\"\"Eta: numeric-categorical correlation\"\"\"\n",
    "    if categories.nunique() < 2:\n",
    "        return np.nan\n",
    "    mask = ~(categories.isna() | values.isna())\n",
    "    categories = categories[mask]\n",
    "    values = values[mask]\n",
    "    overall_mean = values.mean()\n",
    "    cat_means = values.groupby(categories).mean()\n",
    "    cat_counts = categories.value_counts()\n",
    "    numerator = ((cat_means - overall_mean)**2 * cat_counts).sum()\n",
    "    denominator = ((values - overall_mean)**2).sum()\n",
    "    if denominator == 0:\n",
    "        return np.nan\n",
    "    return np.sqrt(numerator / denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf74f8d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     30\u001b[39m     corr = cramers_v(x, y)\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m col1 \u001b[38;5;129;01min\u001b[39;00m cat_cols \u001b[38;5;129;01mand\u001b[39;00m col2 \u001b[38;5;129;01min\u001b[39;00m num_cols:\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     corr = \u001b[43mcorrelation_ratio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m col1 \u001b[38;5;129;01min\u001b[39;00m num_cols \u001b[38;5;129;01mand\u001b[39;00m col2 \u001b[38;5;129;01min\u001b[39;00m cat_cols:\n\u001b[32m     34\u001b[39m     corr = correlation_ratio(y, x)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mcorrelation_ratio\u001b[39m\u001b[34m(categories, values)\u001b[39m\n\u001b[32m     24\u001b[39m values = values[mask]\n\u001b[32m     25\u001b[39m overall_mean = values.mean()\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m cat_means = \u001b[43mvalues\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m cat_counts = categories.value_counts()\n\u001b[32m     28\u001b[39m numerator = ((cat_means - overall_mean)**\u001b[32m2\u001b[39m * cat_counts).sum()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:2458\u001b[39m, in \u001b[36mGroupBy.mean\u001b[39m\u001b[34m(self, numeric_only, engine, engine_kwargs)\u001b[39m\n\u001b[32m   2451\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._numba_agg_general(\n\u001b[32m   2452\u001b[39m         grouped_mean,\n\u001b[32m   2453\u001b[39m         executor.float_dtype_mapping,\n\u001b[32m   2454\u001b[39m         engine_kwargs,\n\u001b[32m   2455\u001b[39m         min_periods=\u001b[32m0\u001b[39m,\n\u001b[32m   2456\u001b[39m     )\n\u001b[32m   2457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2458\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cython_agg_general\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2459\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2460\u001b[39m \u001b[43m        \u001b[49m\u001b[43malt\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2461\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2462\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2463\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result.__finalize__(\u001b[38;5;28mself\u001b[39m.obj, method=\u001b[33m\"\u001b[39m\u001b[33mgroupby\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:2004\u001b[39m, in \u001b[36mGroupBy._cython_agg_general\u001b[39m\u001b[34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[39m\n\u001b[32m   2001\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._agg_py_fallback(how, values, ndim=data.ndim, alt=alt)\n\u001b[32m   2002\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m-> \u001b[39m\u001b[32m2004\u001b[39m new_mgr = \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgrouped_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2005\u001b[39m res = \u001b[38;5;28mself\u001b[39m._wrap_agged_manager(new_mgr)\n\u001b[32m   2006\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33midxmin\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33midxmax\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/internals/base.py:367\u001b[39m, in \u001b[36mSingleDataManager.grouped_reduce\u001b[39m\u001b[34m(self, func)\u001b[39m\n\u001b[32m    365\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgrouped_reduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func):\n\u001b[32m    366\u001b[39m     arr = \u001b[38;5;28mself\u001b[39m.array\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m     res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    368\u001b[39m     index = default_index(\u001b[38;5;28mlen\u001b[39m(res))\n\u001b[32m    370\u001b[39m     mgr = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_array(res, index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1979\u001b[39m, in \u001b[36mGroupBy._cython_agg_general.<locals>.array_func\u001b[39m\u001b[34m(values)\u001b[39m\n\u001b[32m   1977\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34marray_func\u001b[39m(values: ArrayLike) -> ArrayLike:\n\u001b[32m   1978\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1979\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_grouper\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_cython_operation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1980\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maggregate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1981\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1982\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1983\u001b[39m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mndim\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1984\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1985\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1986\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1987\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[32m   1988\u001b[39m         \u001b[38;5;66;03m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[32m   1989\u001b[39m         \u001b[38;5;66;03m# and non-applicable functions\u001b[39;00m\n\u001b[32m   1990\u001b[39m         \u001b[38;5;66;03m# try to python agg\u001b[39;00m\n\u001b[32m   1991\u001b[39m         \u001b[38;5;66;03m# TODO: shouldn't min_count matter?\u001b[39;00m\n\u001b[32m   1992\u001b[39m         \u001b[38;5;66;03m# TODO: avoid special casing SparseArray here\u001b[39;00m\n\u001b[32m   1993\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33many\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mall\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, SparseArray):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/ops.py:827\u001b[39m, in \u001b[36mBaseGrouper._cython_operation\u001b[39m\u001b[34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    823\u001b[39m \u001b[33;03mReturns the values of a cython operation.\u001b[39;00m\n\u001b[32m    824\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    825\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m kind \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33maggregate\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m827\u001b[39m cy_op = WrappedCythonOp(kind=kind, how=how, has_dropped_na=\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhas_dropped_na\u001b[49m)\n\u001b[32m    829\u001b[39m ids, _, _ = \u001b[38;5;28mself\u001b[39m.group_info\n\u001b[32m    830\u001b[39m ngroups = \u001b[38;5;28mself\u001b[39m.ngroups\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/properties.pyx:36\u001b[39m, in \u001b[36mpandas._libs.properties.CachedProperty.__get__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/ops.py:741\u001b[39m, in \u001b[36mBaseGrouper.has_dropped_na\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[32m    737\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhas_dropped_na\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    738\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    739\u001b[39m \u001b[33;03m    Whether grouper has null value(s) that are dropped.\u001b[39;00m\n\u001b[32m    740\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m741\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m((\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroup_info\u001b[49m[\u001b[32m0\u001b[39m] < \u001b[32m0\u001b[39m).any())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/properties.pyx:36\u001b[39m, in \u001b[36mpandas._libs.properties.CachedProperty.__get__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/ops.py:745\u001b[39m, in \u001b[36mBaseGrouper.group_info\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    743\u001b[39m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[32m    744\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgroup_info\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mtuple\u001b[39m[npt.NDArray[np.intp], npt.NDArray[np.intp], \u001b[38;5;28mint\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m745\u001b[39m     comp_ids, obs_group_ids = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_compressed_codes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    747\u001b[39m     ngroups = \u001b[38;5;28mlen\u001b[39m(obs_group_ids)\n\u001b[32m    748\u001b[39m     comp_ids = ensure_platform_int(comp_ids)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/ops.py:769\u001b[39m, in \u001b[36mBaseGrouper._get_compressed_codes\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    766\u001b[39m     \u001b[38;5;66;03m# FIXME: compress_group_index's second return value is int64, not intp\u001b[39;00m\n\u001b[32m    768\u001b[39m ping = \u001b[38;5;28mself\u001b[39m.groupings[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m769\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mping\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcodes\u001b[49m, np.arange(\u001b[38;5;28mlen\u001b[39m(ping._group_index), dtype=np.intp)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/grouper.py:691\u001b[39m, in \u001b[36mGrouping.codes\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    689\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    690\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcodes\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> npt.NDArray[np.signedinteger]:\n\u001b[32m--> \u001b[39m\u001b[32m691\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_codes_and_uniques\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/properties.pyx:36\u001b[39m, in \u001b[36mpandas._libs.properties.CachedProperty.__get__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/grouper.py:835\u001b[39m, in \u001b[36mGrouping._codes_and_uniques\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    830\u001b[39m     uniques = \u001b[38;5;28mself\u001b[39m._uniques\n\u001b[32m    831\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    832\u001b[39m     \u001b[38;5;66;03m# GH35667, replace dropna=False with use_na_sentinel=False\u001b[39;00m\n\u001b[32m    833\u001b[39m     \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type \"Union[\u001b[39;00m\n\u001b[32m    834\u001b[39m     \u001b[38;5;66;03m# ndarray[Any, Any], Index]\", variable has type \"Categorical\")\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m835\u001b[39m     codes, uniques = \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[32m    836\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgrouping_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dropna\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m codes, uniques\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/algorithms.py:802\u001b[39m, in \u001b[36mfactorize\u001b[39m\u001b[34m(values, sort, use_na_sentinel, size_hint)\u001b[39m\n\u001b[32m    795\u001b[39m     codes, uniques = factorize_array(\n\u001b[32m    796\u001b[39m         values,\n\u001b[32m    797\u001b[39m         use_na_sentinel=use_na_sentinel,\n\u001b[32m    798\u001b[39m         size_hint=size_hint,\n\u001b[32m    799\u001b[39m     )\n\u001b[32m    801\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m802\u001b[39m     uniques, codes = \u001b[43msafe_sort\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[43m        \u001b[49m\u001b[43muniques\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    805\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    806\u001b[39m \u001b[43m        \u001b[49m\u001b[43massume_unique\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    807\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    808\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    810\u001b[39m uniques = _reconstruct_data(uniques, original.dtype, original)\n\u001b[32m    812\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m codes, uniques\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/algorithms.py:1516\u001b[39m, in \u001b[36msafe_sort\u001b[39m\u001b[34m(values, codes, use_na_sentinel, assume_unique, verify)\u001b[39m\n\u001b[32m   1514\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1515\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1516\u001b[39m         sorter = values.argsort()\n\u001b[32m   1517\u001b[39m         ordered = values.take(sorter)\n\u001b[32m   1518\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, decimal.InvalidOperation):\n\u001b[32m   1519\u001b[39m         \u001b[38;5;66;03m# Previous sorters failed or were not applicable, try `_sort_mixed`\u001b[39;00m\n\u001b[32m   1520\u001b[39m         \u001b[38;5;66;03m# which would work, but which fails for special case of 1d arrays\u001b[39;00m\n\u001b[32m   1521\u001b[39m         \u001b[38;5;66;03m# with tuples.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Build full correlation matrix\n",
    "# WARNING: THIS TAKES A LONG TIME TO RUN AND YOU PROBABLY DON'T\n",
    "# NEED TO RUN THIS AGAIN. JUST ASK @ANNIE FOR THE FILE\n",
    "\n",
    "df = train.copy()\n",
    "\n",
    "for col in df.select_dtypes(include=[\"datetime\", \"datetimetz\"]).columns:\n",
    "    df[col] = df[col].astype(str)\n",
    "for col in df.select_dtypes(include=[\"object\", \"category\"]).columns:\n",
    "    df[col] = df[col].astype(str)\n",
    "\n",
    "cat_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "num_cols = df.select_dtypes(include=[\"number\"]).columns\n",
    "\n",
    "cols = df.columns\n",
    "corr_matrix = pd.DataFrame(index=cols, columns=cols, dtype=float)\n",
    "\n",
    "for col1 in cols:\n",
    "    for col2 in cols:\n",
    "        if col1 == col2:\n",
    "            corr_matrix.loc[col1, col2] = 1.0\n",
    "            continue\n",
    "        \n",
    "        x = df[col1]\n",
    "        y = df[col2]\n",
    "\n",
    "        if col1 in num_cols and col2 in num_cols:\n",
    "            corr = x.corr(y)\n",
    "        elif col1 in cat_cols and col2 in cat_cols:\n",
    "            corr = cramers_v(x, y)\n",
    "        elif col1 in cat_cols and col2 in num_cols:\n",
    "            corr = correlation_ratio(x, y)\n",
    "        elif col1 in num_cols and col2 in cat_cols:\n",
    "            corr = correlation_ratio(y, x)\n",
    "\n",
    "        corr_matrix.loc[col1, col2] = corr\n",
    "\n",
    "print(\"Full mixed-type correlation matrix computed (no errors!).\")\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c843436",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corr_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Save the correlation matrix so will never have to run that correlation matrix again\u001b[39;00m\n\u001b[32m      2\u001b[39m corr_pairs = (\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mcorr_matrix\u001b[49m.stack()\n\u001b[32m      4\u001b[39m     .reset_index()\n\u001b[32m      5\u001b[39m     .rename(columns={\u001b[33m\"\u001b[39m\u001b[33mlevel_0\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mFeature1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlevel_1\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mFeature2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mCorrelation\u001b[39m\u001b[33m\"\u001b[39m})\n\u001b[32m      6\u001b[39m )\n\u001b[32m      8\u001b[39m corr_pairs = corr_pairs[corr_pairs[\u001b[33m\"\u001b[39m\u001b[33mFeature1\u001b[39m\u001b[33m\"\u001b[39m] < corr_pairs[\u001b[33m\"\u001b[39m\u001b[33mFeature2\u001b[39m\u001b[33m\"\u001b[39m]]\n\u001b[32m      9\u001b[39m corr_pairs = corr_pairs[\n\u001b[32m     10\u001b[39m     (corr_pairs[\u001b[33m\"\u001b[39m\u001b[33mFeature1\u001b[39m\u001b[33m\"\u001b[39m] != \u001b[33m\"\u001b[39m\u001b[33mCattle_ID\u001b[39m\u001b[33m\"\u001b[39m) &\n\u001b[32m     11\u001b[39m     (corr_pairs[\u001b[33m\"\u001b[39m\u001b[33mFeature2\u001b[39m\u001b[33m\"\u001b[39m] != \u001b[33m\"\u001b[39m\u001b[33mCattle_ID\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m ]\n",
      "\u001b[31mNameError\u001b[39m: name 'corr_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the correlation matrix so will never have to run that correlation matrix again\n",
    "corr_pairs = (\n",
    "    corr_matrix.stack()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"level_0\": \"Feature1\", \"level_1\": \"Feature2\", 0: \"Correlation\"})\n",
    ")\n",
    "\n",
    "corr_pairs = corr_pairs[corr_pairs[\"Feature1\"] < corr_pairs[\"Feature2\"]]\n",
    "corr_pairs = corr_pairs[\n",
    "    (corr_pairs[\"Feature1\"] != \"Cattle_ID\") &\n",
    "    (corr_pairs[\"Feature2\"] != \"Cattle_ID\")\n",
    "]\n",
    "corr_pairs = corr_pairs.iloc[corr_pairs[\"Correlation\"].abs().argsort()[::-1]]\n",
    "corr_pairs.to_csv(\"correlation_pairs_sorted.csv\", index=False)\n",
    "print(\"Saved sorted pairwise correlations to correlation_pairs_sorted.csv\")\n",
    "\n",
    "\"\"\" \n",
    "After getting all the pairwise correlations, we've seen that the maximum correlation\n",
    "between two pairs is around 30%, so nothing too much of note we've determined.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8aa0209e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as farm_climate_zone_counts.csv\n",
      "Climate_Zone  Arid  Continental  Mediterranean  Subtropical  Temperate  \\\n",
      "Farm_ID                                                                  \n",
      "FARM_0001       27           37             30           36         27   \n",
      "FARM_0002       35           34             28           35         40   \n",
      "FARM_0003       29           35             36           37         40   \n",
      "FARM_0004       31           41             34           38         44   \n",
      "FARM_0005       35           34             45           24         33   \n",
      "\n",
      "Climate_Zone  Tropical  \n",
      "Farm_ID                 \n",
      "FARM_0001           42  \n",
      "FARM_0002           28  \n",
      "FARM_0003           27  \n",
      "FARM_0004           40  \n",
      "FARM_0005           42  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cattle_ID</th>\n",
       "      <th>Breed</th>\n",
       "      <th>Management_System</th>\n",
       "      <th>Age_Months</th>\n",
       "      <th>Weight_kg</th>\n",
       "      <th>Parity</th>\n",
       "      <th>Lactation_Stage</th>\n",
       "      <th>Days_in_Milk</th>\n",
       "      <th>Feed_Type</th>\n",
       "      <th>Feed_Quantity_kg</th>\n",
       "      <th>...</th>\n",
       "      <th>IBR_Vaccine</th>\n",
       "      <th>BVD_Vaccine</th>\n",
       "      <th>Rabies_Vaccine</th>\n",
       "      <th>Previous_Week_Avg_Yield</th>\n",
       "      <th>Body_Condition_Score</th>\n",
       "      <th>Milking_Interval_hrs</th>\n",
       "      <th>Date</th>\n",
       "      <th>Farm_ID</th>\n",
       "      <th>Mastitis</th>\n",
       "      <th>Milk_Yield_L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CATTLE_133713</td>\n",
       "      <td>Holstein</td>\n",
       "      <td>Intensive</td>\n",
       "      <td>114</td>\n",
       "      <td>544.8</td>\n",
       "      <td>4</td>\n",
       "      <td>Mid</td>\n",
       "      <td>62</td>\n",
       "      <td>Concentrates</td>\n",
       "      <td>16.363455</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.31</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12</td>\n",
       "      <td>2024-01-15</td>\n",
       "      <td>FARM_0301</td>\n",
       "      <td>1</td>\n",
       "      <td>12.192634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CATTLE_027003</td>\n",
       "      <td>Holstein</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>136</td>\n",
       "      <td>298.9</td>\n",
       "      <td>4</td>\n",
       "      <td>Mid</td>\n",
       "      <td>213</td>\n",
       "      <td>Crop_Residues</td>\n",
       "      <td>12.014374</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.16</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12</td>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>FARM_0219</td>\n",
       "      <td>0</td>\n",
       "      <td>14.717031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CATTLE_122459</td>\n",
       "      <td>Holstein</td>\n",
       "      <td>Semi_Intensive</td>\n",
       "      <td>64</td>\n",
       "      <td>336.6</td>\n",
       "      <td>4</td>\n",
       "      <td>Late</td>\n",
       "      <td>16</td>\n",
       "      <td>Hay</td>\n",
       "      <td>7.198607</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.07</td>\n",
       "      <td>3.5</td>\n",
       "      <td>12</td>\n",
       "      <td>2024-05-20</td>\n",
       "      <td>FARM_0802</td>\n",
       "      <td>0</td>\n",
       "      <td>14.006142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CATTLE_213419</td>\n",
       "      <td>Jersey</td>\n",
       "      <td>Intensive</td>\n",
       "      <td>58</td>\n",
       "      <td>370.5</td>\n",
       "      <td>1</td>\n",
       "      <td>Early</td>\n",
       "      <td>339</td>\n",
       "      <td>Crop_Residues</td>\n",
       "      <td>18.694344</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.23</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24</td>\n",
       "      <td>2024-07-22</td>\n",
       "      <td>FARM_0034</td>\n",
       "      <td>0</td>\n",
       "      <td>24.324325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CATTLE_106260</td>\n",
       "      <td>Guernsey</td>\n",
       "      <td>Intensive</td>\n",
       "      <td>84</td>\n",
       "      <td>641.5</td>\n",
       "      <td>6</td>\n",
       "      <td>Early</td>\n",
       "      <td>125</td>\n",
       "      <td>Mixed_Feed</td>\n",
       "      <td>14.779198</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.68</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>FARM_0695</td>\n",
       "      <td>1</td>\n",
       "      <td>12.023074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Cattle_ID     Breed Management_System  Age_Months  Weight_kg  Parity  \\\n",
       "0  CATTLE_133713  Holstein         Intensive         114      544.8       4   \n",
       "1  CATTLE_027003  Holstein             Mixed         136      298.9       4   \n",
       "2  CATTLE_122459  Holstein    Semi_Intensive          64      336.6       4   \n",
       "3  CATTLE_213419    Jersey         Intensive          58      370.5       1   \n",
       "4  CATTLE_106260  Guernsey         Intensive          84      641.5       6   \n",
       "\n",
       "  Lactation_Stage  Days_in_Milk      Feed_Type  Feed_Quantity_kg  ...  \\\n",
       "0             Mid            62   Concentrates         16.363455  ...   \n",
       "1             Mid           213  Crop_Residues         12.014374  ...   \n",
       "2            Late            16            Hay          7.198607  ...   \n",
       "3           Early           339  Crop_Residues         18.694344  ...   \n",
       "4           Early           125     Mixed_Feed         14.779198  ...   \n",
       "\n",
       "   IBR_Vaccine  BVD_Vaccine  Rabies_Vaccine  Previous_Week_Avg_Yield  \\\n",
       "0            1            0               1                     6.31   \n",
       "1            0            0               0                    17.16   \n",
       "2            1            1               0                     4.07   \n",
       "3            0            0               0                    10.23   \n",
       "4            0            1               1                    20.68   \n",
       "\n",
       "   Body_Condition_Score  Milking_Interval_hrs       Date    Farm_ID  Mastitis  \\\n",
       "0                   3.0                    12 2024-01-15  FARM_0301         1   \n",
       "1                   4.0                    12 2023-10-31  FARM_0219         0   \n",
       "2                   3.5                    12 2024-05-20  FARM_0802         0   \n",
       "3                   3.0                    24 2024-07-22  FARM_0034         0   \n",
       "4                   3.0                    12 2023-01-03  FARM_0695         1   \n",
       "\n",
       "   Milk_Yield_L  \n",
       "0     12.192634  \n",
       "1     14.717031  \n",
       "2     14.006142  \n",
       "3     24.324325  \n",
       "4     12.023074  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "We are a little confused as to why Farm_ID and Climate_Zone have 0 correlation. After\n",
    "a little more data exploration, we found out that each Farm_ID roughly has an equal\n",
    "number of each Climate_Zone, which is a little confusing since to us, logically, one\n",
    "Farm_ID represents one farm in one location and therefore should be in one Climate_Zone.\n",
    "In addition, we have enough other temperature related features that we think it is alright\n",
    "to drop this one. Therefore, we are dropping the Climate_Zone column completely.\n",
    "\n",
    "From the correlation pairings, this is the only pairing with a 0 correlation score that\n",
    "doesn't really make sense, so on the basis of correlation pairing, that's the only feature\n",
    "we will drop.\n",
    "\"\"\"\n",
    "climate_counts = pd.crosstab(train['Farm_ID'], train['Climate_Zone'])\n",
    "\n",
    "climate_counts.to_csv(\"farm_climate_zone_counts.csv\")\n",
    "\n",
    "print(\"Saved as farm_climate_zone_counts.csv\")\n",
    "print(climate_counts.head())\n",
    "\n",
    "train = train.drop(\"Climate_Zone\", axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9062849e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               mean         std         min         max\n",
      "Age_Months                83.473243   34.647286   24.000000  143.000000\n",
      "Weight_kg                499.968245  144.651856  250.000000  750.000000\n",
      "Parity                     3.499967    1.707315    1.000000    6.000000\n",
      "Days_in_Milk             182.059226  105.029984    1.000000  364.000000\n",
      "Feed_Quantity_kg          12.015898    3.868669    2.370284   25.454207\n",
      "Feeding_Frequency          2.999081    1.413191    1.000000    5.000000\n",
      "Water_Intake_L            80.037438   14.987507   14.207737  149.960210\n",
      "Walking_Distance_km        4.034781    1.928525    0.500000   12.000000\n",
      "Grazing_Duration_hrs       6.056783    2.867601    1.000000   14.000000\n",
      "Resting_Hours             10.067635    2.865592    5.000000   18.000000\n",
      "Ambient_Temperature_C     21.883828   11.695378  -11.863353   47.192325\n",
      "Humidity_percent          59.813006   19.489647   10.000000  100.000000\n",
      "Housing_Score              0.649079    0.199482    0.269460    1.033372\n",
      "FMD_Vaccine                0.599292    0.490043    0.000000    1.000000\n",
      "Brucellosis_Vaccine        0.600073    0.489884    0.000000    1.000000\n",
      "HS_Vaccine                 0.599659    0.489969    0.000000    1.000000\n",
      "BQ_Vaccine                 0.600716    0.489752    0.000000    1.000000\n",
      "Anthrax_Vaccine            0.600412    0.489815    0.000000    1.000000\n",
      "IBR_Vaccine                0.598849    0.490133    0.000000    1.000000\n",
      "BVD_Vaccine                0.599792    0.489941    0.000000    1.000000\n",
      "Rabies_Vaccine             0.600926    0.489709    0.000000    1.000000\n",
      "Previous_Week_Avg_Yield    8.748664    5.901607    0.000000   38.670000\n",
      "Body_Condition_Score       3.394787    0.632816    2.000000    5.000000\n",
      "Milking_Interval_hrs      12.302602    4.299149    6.000000   24.000000\n",
      "Mastitis                   0.099959    0.299946    0.000000    1.000000\n",
      "Milk_Yield_L              15.595179    5.343345    0.055212   44.555285\n",
      "Saved to numerical_feature_summary.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" \\nFrom this, we manually looked through and determined most of the min and max's were\\npretty possible so we will keep this.\\n\""
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "Now we want to look for outliers in our code so we will describe every numerical feature.\n",
    "\"\"\"\n",
    "numerical_cols = train.select_dtypes(include=[\"number\"]).columns\n",
    "full_desc = train[numerical_cols].describe()\n",
    "num_summary = full_desc.loc[[\"mean\", \"std\", \"min\", \"max\"]].T\n",
    "print(num_summary)\n",
    "\n",
    "num_summary.to_csv(\"numerical_feature_summary.csv\")\n",
    "print(\"Saved to numerical_feature_summary.csv\")\n",
    "\n",
    "\"\"\" \n",
    "From this, we manually looked through and determined most of the min and max's were\n",
    "pretty possible so we will keep this.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9587e209",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Now time to make the categorical features a little more efficient by converting them.\n",
    "One Hot Encode:\n",
    "- Breed\n",
    "- Management_System\n",
    "Change to Ranges:\n",
    "- Lactation_Stage (Early, Mid, Late)\n",
    "Farm_ID: will be converted to the ranking of how much milk the farm produces.\n",
    "i.e. if FARM_0301 has a cow that produces 30L and 24.2L and is the most, that\n",
    "FARM_ID will be 1.\n",
    "Date: convert to ordinal days from a base date of 2000-01-01.\n",
    "\"\"\"\n",
    "# 1. One-hot encode selected columns\n",
    "onehot_cols = [\"Breed\", \"Management_System\"]\n",
    "\n",
    "train = pd.get_dummies(train, columns=onehot_cols, prefix=onehot_cols, drop_first=True)\n",
    "\n",
    "# 2. Numeric encoding for Lactation_Stage\n",
    "stage_map = {\"Early\": 1, \"Mid\": 2, \"Late\": 3}\n",
    "train[\"Lactation_Stage\"] = train[\"Lactation_Stage\"].map(stage_map).astype(int)\n",
    "\n",
    "# 3. Farm_ID → rank based on farm’s average milk yield\n",
    "farm_mean_yield = train.groupby(\"Farm_ID\")[\"Milk_Yield_L\"].mean()\n",
    "farm_rank = farm_mean_yield.rank(method=\"dense\", ascending=False).astype(int)\n",
    "train[\"Farm_ID\"] = train[\"Farm_ID\"].map(farm_rank)\n",
    "\n",
    "# 4. Date → ordinal days since 2000-01-01\n",
    "base_date = pd.to_datetime(\"2000-01-01\")\n",
    "train[\"Date_Ordinal\"] = (train[\"Date\"] - base_date).dt.days\n",
    "\n",
    "train = train.drop(columns=[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "fd32e464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_train_data.csv\n"
     ]
    }
   ],
   "source": [
    "train.to_csv(\"cleaned_train_data.csv\", index=False)\n",
    "print(\"Saved cleaned_train_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6383550e",
   "metadata": {},
   "source": [
    "Do all the data preparation to the testing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dbf60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# APPLY SAME CLEANING TO TEST\n",
    "# ------------------------------\n",
    "\n",
    "test = pd.read_csv(TEST_PATH)\n",
    "\n",
    "# 1) REMOVE NEGATIVES WHERE THEY ARE INVALID\n",
    "non_negative_cols = [\n",
    "    \"Age_Months\", \"Weight_kg\", \"Parity\", \"Days_in_Milk\",\n",
    "    \"Feed_Quantity_kg\", \"Water_Intake_L\", \"Walking_Distance_km\",\n",
    "    \"Grazing_Duration_hrs\", \"Resting_Hours\", \"Humidity_percent\",\n",
    "    \"Previous_Week_Avg_Yield\", \"Milking_Interval_hrs\", \"Feed_Quantity_lb\"\n",
    "]\n",
    "\n",
    "for col in non_negative_cols:\n",
    "    if col in test.columns:\n",
    "        test.loc[test[col] < 0, col] = np.nan  # replace with NaN, then impute if needed\n",
    "\n",
    "\n",
    "# 2) DROP RUMINATION_TIME_HRS (we removed it from train)\n",
    "if \"Rumination_Time_hrs\" in test.columns:\n",
    "    test = test.drop(columns=[\"Rumination_Time_hrs\"])\n",
    "\n",
    "\n",
    "# 3) IMPUTE HOUSING SCORE USING GROUP-BY FARM_ID + DATE (same as train)\n",
    "\n",
    "# Prepare helper means computed from train\n",
    "test_hs = test.dropna(subset=[\"Housing_Score\"])\n",
    "farm_date_means = test_hs.groupby([\"Farm_ID\"])[\"Housing_Score\"].mean()\n",
    "farm_means = test_hs.groupby(\"Farm_ID\")[\"Housing_Score\"].mean()\n",
    "global_mean_hs = train[\"Housing_Score\"].mean()\n",
    "\n",
    "def impute_hs(row):\n",
    "    farm = row[\"Farm_ID\"]\n",
    "    if pd.isna(row[\"Housing_Score\"]):\n",
    "        # Try exact Farm + Date\n",
    "        if farm in farm_date_means.index:\n",
    "            return farm_date_means.loc[farm]\n",
    "        # Fall back to Farm_ID mean\n",
    "        if farm in farm_means.index:\n",
    "            return farm_means.loc[farm]\n",
    "        # Global fallback\n",
    "        return global_mean_hs\n",
    "    return row[\"Housing_Score\"]\n",
    "\n",
    "test[\"Housing_Score\"] = test.apply(impute_hs, axis=1)\n",
    "\n",
    "\n",
    "# 4) IMPUTE FEED_QUANTITY_KG USING BREED-GROUP MEANS (same as our final decision)\n",
    "\n",
    "breed_means_fq = test.groupby(\"Breed\")[\"Feed_Quantity_kg\"].mean()\n",
    "global_mean_fq = test[\"Feed_Quantity_kg\"].mean()\n",
    "\n",
    "def impute_feed(row):\n",
    "    if pd.isna(row[\"Feed_Quantity_kg\"]):\n",
    "        b = row[\"Breed\"]\n",
    "        if b in breed_means_fq.index:\n",
    "            return breed_means_fq.loc[b]\n",
    "        return global_mean_fq\n",
    "    return row[\"Feed_Quantity_kg\"]\n",
    "\n",
    "test[\"Feed_Quantity_kg\"] = test.apply(impute_feed, axis=1)\n",
    "test.drop(columns=\"Feed_Quantity_lb\")\n",
    "\n",
    "\n",
    "# # 5) CONVERT CATEGORICALS TO CATEGORY TYPE\n",
    "# cat_cols = train.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "# for col in cat_cols:\n",
    "#     if col in test.columns:\n",
    "#         test[col] = test[col].astype(\"category\")\n",
    "\n",
    "# 6) DROP CLIMATE_ZONE (same as train)\n",
    "test = test.drop(\"Climate_Zone\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "46b93c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset fully cleaned + feature engineered.\n",
      "Saved cleaned_test_data.csv\n"
     ]
    }
   ],
   "source": [
    "# 7) FEATURE ENGINEERING SAME AS TRAIN\n",
    "# ============================\n",
    "# SECTION 2: PREPARE TEST SET\n",
    "# ============================\n",
    "\n",
    "# 1. One-hot encode same columns\n",
    "test = pd.get_dummies(test, columns=onehot_cols, prefix=onehot_cols, drop_first=True)\n",
    "\n",
    "# 2. Numeric encoding for Lactation_Stage\n",
    "test[\"Lactation_Stage\"] = test[\"Lactation_Stage\"].map(stage_map).astype(int)\n",
    "\n",
    "# 3. Farm_ID → use TRAIN-derived mapping\n",
    "farmid_map = farm_rank.to_dict()\n",
    "test[\"Farm_ID\"] = test[\"Farm_ID\"].map(farmid_map)\n",
    "\n",
    "# Assign a fallback value for unseen farms\n",
    "unknown_rank = max(farmid_map.values()) + 1\n",
    "test[\"Farm_ID\"] = test[\"Farm_ID\"].fillna(unknown_rank).astype(int)\n",
    "\n",
    "# 4. Date → ordinal days since 2000-01-01\n",
    "test[\"Date\"] = pd.to_datetime(test[\"Date\"], errors=\"coerce\")\n",
    "test[\"Date_Ordinal\"] = (test[\"Date\"] - base_date).dt.days\n",
    "\n",
    "# Drop the original Date column\n",
    "test = test.drop(columns=[\"Date\"])\n",
    "\n",
    "# 5. Align one-hot encoded columns with train\n",
    "train, test = train.align(test, join=\"left\", axis=1, fill_value=0)\n",
    "\n",
    "print(\"Test dataset fully cleaned + feature engineered.\")\n",
    "\n",
    "test.to_csv(\"cleaned_test_data.csv\", index=False)\n",
    "print(\"Saved cleaned_test_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
